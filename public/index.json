[{"authors":["admin"],"categories":null,"content":"Dr Christian Ryan is a Senior Lecturer in Clinical Psychology in the School of Applied Psychology at University College Cork. He is the placement coordinator for the DClinPsych programme.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Dr Christian Ryan is a Senior Lecturer in Clinical Psychology in the School of Applied Psychology at University College Cork. He is the placement coordinator for the DClinPsych programme.","tags":null,"title":"Christian Ryan","type":"authors"},{"authors":null,"categories":null,"content":" Flexibility This feature can be used for publishing content such as:\n Online courses Project or software documentation Tutorials  The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026quot;Courses\u0026quot; url = \u0026quot;courses/\u0026quot; weight = 50  Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026quot;Docs\u0026quot; url = \u0026quot;docs/\u0026quot; weight = 50  Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"/courses/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":" In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"74533bae41439377bd30f645c4677a27","permalink":"/courses/example/example1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example1/","section":"courses","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":" Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"1c2b5a11257c768c90d5050637d77d6a","permalink":"/courses/example/example2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example2/","section":"courses","summary":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":[],"categories":["R coding"],"content":" In the previous post on ‘pulling text data from the internet’, I experimented with pulling out the dream text from a sample of dreams from the website “DreamBank” at: http://www.dreambank.net/random_sample.cgi.\nIn this follow-up post, I will demonstrate some of the methods presented in Julia Silge and David Robinson’s book ‘Text Mining with R’ for processing text data, as applied to 400 dreams sampled from 4 collections in the dreambank. I used the methods described in the last post to pull out a random sample of 100 dreams from each of the following 4 groups:\n college_women (this was the sample used last time) hall_female hall_male vietnam_vet  The first set of dreams were recorded by college women by Calvin Hall from undergraduates in a course on personality at Western Reserve University in 1947 and 1948.\nThe second and third samples are also dreams collected by Calvin Hall and Robert L. Van de Castle, on which they based female and male norms in their book The Content Analysis of Dreams.\nThe sample listed as vietnam_vet are from the dreams of an American veteran of the Vietnam war, who suffered PTSD. The website has over 400 of his dreams which he donated from records he kept not long after returning from Vietnam.\nLet’s begin by loading the three packages we are likely to use.\nlibrary(tidyverse) library(tidytext) library(stringr) If you want to follow along with this post, the dataset I am about to load is “dream_df.csv”, which can be found on my github page: https://github.com/Christian-Ryan/netsite/tree/master/public/post\ndf \u0026lt;- read_csv(\u0026quot;dreams_df.csv\u0026quot;) df \u0026lt;- df[,2:3] df$sample \u0026lt;- as.factor(df$sample) After sampling the four dream sets, using the techniques described in the last post, we now have a dataframe called df with two variables - sample and dream. We will use our custom_view() function we created last time to display snippets of dreams neatly formatted. We can also use the some() function from the car package to take a quick look at a selection of dreams across the dataframe. The some() function is very like head() and tail(), but has the advantage of returning a selection across the dataset, which allows us to see examples from each of the samples simultaneously.\ncustom_view \u0026lt;- function(x) data.frame(lapply(x, substr, 1, 56)) car::some(df) %\u0026gt;% custom_view() ## sample dream ## 1 college_women I was dreaming about taking some sort of trip. I arrange ## 2 vietnam_vet I\u0026#39;m in Honduras at some kind of border crossing. A wide ## 3 vietnam_vet I\u0026#39;m staying in a cozy house with two young doctors, a ha ## 4 hall_male My father, brother (17) and I were traveling to Toledo ( ## 5 hall_male I was a spy in a house in which there seemed to be a par ## 6 hall_male I was driving my car along a dark road. All of a sudden ## 7 hall_male I was seated at a card table playing poker with three ot ## 8 hall_female I dreamed of 2 girls (I know them personally and always ## 9 hall_female This dream concerns an artist friend of my husband\u0026#39;s. He ## 10 hall_female I was in a strange house in the town we lived in about 1 Julia Silge and David Robinson’s book Text Mining with R - A tidy approach sets off at a cracking pace, at least for relatively newbies to R such as myself. They assumes a degree of familiarity with tidyverse concepts and when they introduce concepts such as tidytext format, they can sometimes address three or four steps in one example. I will unpack some of these as individual steps to illustrate what is going on, while using our dream data as the material for processing.\nAt the moment our df only contains the sample name (a categorical variable with four values) and the text of the dream. It might be helpful to index the dreams before we tokenise the text in them. So let’s introduce a new variable that we will call dream_number. This will index each dream between 1 - 400 in the dataframe.\ndf \u0026lt;- df %\u0026gt;% mutate(dream_number = row_number()) Now we have the dream_number variable added, we can unnest the tokens (split the text variable into individual words). The syntax for the unnest_tokens() function is to pipe in the dataframe (df), then supply the name of the variable to be created (word), followed by the variable containing the text we are going to tokenise - in this case “dream”.\ndf_word \u0026lt;- df %\u0026gt;% unnest_tokens(word, dream) head(df_word) ## # A tibble: 6 x 3 ## sample dream_number word ## \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; ## 1 college_women 1 i ## 2 college_women 1 dreamed ## 3 college_women 1 that ## 4 college_women 1 i ## 5 college_women 1 was ## 6 college_women 1 in See that the word variable has replaced our dream variable and now each word is on a separate row - this is the tidytext format. unnest_tokens() has kept the variables sample and dream_number - it only transforms the input variable (dream) into the output variable (word). Notice also that the function has transformed into lower-case all the words in the word variable.\nTokenisation and N-Grams  It should be noted that when we use unnest_tokens() we are using a range of default values. We could have specified something other than single words in our output. The default value of the token argument is ‘word’. We can change this to ‘ngram’ and use an ‘n=’ to specify how many words should be kept as a group. Let us try a quick run with 3-word tokens instead of single words to demonstrate this behaviour.\ndf_trigrams \u0026lt;- df %\u0026gt;% unnest_tokens(trigrams, dream, token = \u0026quot;ngrams\u0026quot;, n = 3) head(df_trigrams) ## # A tibble: 6 x 3 ## sample dream_number trigrams ## \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; ## 1 college_women 1 i dreamed that ## 2 college_women 1 dreamed that i ## 3 college_women 1 that i was ## 4 college_women 1 i was in ## 5 college_women 1 was in the ## 6 college_women 1 in the office So here we have set our output variable to ‘trigrams’ and specified the token argument to be equal to ‘ngrams’, and we have saved this as a new dataframe called ‘df_trigrams’. That gives us a better sense of the nature of the text. We can also run a count on this after grouping by sample.\ndf_trigrams %\u0026gt;% group_by(sample) %\u0026gt;% count(trigrams, sort = TRUE) %\u0026gt;% ungroup() ## # A tibble: 50,935 x 3 ## sample trigrams n ## \u0026lt;fct\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; ## 1 vietnam_vet i tell him 33 ## 2 hall_female i was in 29 ## 3 college_women i was in 25 ## 4 vietnam_vet the scene changes 23 ## 5 college_women and i was 22 ## 6 hall_female seemed to be 19 ## 7 college_women that i was 18 ## 8 hall_female that i was 17 ## 9 hall_male seemed to be 17 ## 10 hall_female and i was 16 ## # … with 50,925 more rows Here we can see that in the Vietnam veteran dream sample, the most common three word phrase was “I tell him”, whereas for the Hall Female and College Women the most common phrase was “I was in”. Using ngrams (units larger than one word), can be useful in exploring most frequently occurring phrases. It is notable that the phrase for the Vietnam vet was in the present tense, giving a sense of the immediacy and immersion of the dream experience, whereas those most frequent phrases of the other samples are in the past tense.\n  Single words (Bag of words approach) We have not removed stop-words yet as this would undermine our exploration of ngrams. But this is the next step for our df_word dataset. The anti_join() function, takes two dataframes and keeps only those words that don’t occur in both dataframes. So this forms a convenient and easy way to filter out unwanted stopwords.\ndf_word \u0026lt;- df_word %\u0026gt;% anti_join(stop_words) Then we can count the words and sort them into descending order.\ndf_word %\u0026gt;% count(word, sort = TRUE) ## # A tibble: 5,331 x 2 ## word n ## \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; ## 1 house 133 ## 2 dream 132 ## 3 remember 125 ## 4 car 118 ## 5 people 110 ## 6 girl 108 ## 7 friend 101 ## 8 time 95 ## 9 woman 93 ## 10 mother 85 ## # … with 5,321 more rows But before we create some plots of these words, we should check for any anomalies in the word variable of df_word. The sorted count is likely to give back expected results (high frequency genuine words). But there can be other text elements that we may want to filter out. This will become obvious if we count, but don’t sort.\ndf_word %\u0026gt;% count(word) ## # A tibble: 5,331 x 2 ## word n ## \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; ## 1 ___ 1 ## 2 ______ 1 ## 3 00 2 ## 4 1 4 ## 5 1,500 1 ## 6 10 13 ## 7 100 3 ## 8 105 1 ## 9 107th 1 ## 10 109 1 ## # … with 5,321 more rows The word variable contains some text elements that we would not regard as words. Let’s check where the underscores came from. To do this we must go back to our original (untokenised) dataset df, as we want to see the underscores in the context of the dream. We can use the str_which() function to identify which dreams contain underscores, matched to the pattern '___'. Then we can use this as an index on the df$dream variable, so that it just returns the context of the dreams with underscores. As there are three dreams with underscores, we will store this sequence of dreams and then take a look at the first one.\nunderscores \u0026lt;- df$dream[str_which(df$dream, pattern = \u0026quot;___\u0026quot;)] underscores[1] ## [1] \u0026quot;I dreamed about a young married couple whom I have known for a long time. They came to see us at our home. Although the home was ours, it resembled my Uncle\u0026#39;s home in C___ and yet the dream seemed to take place in C ___.. They drove up in a Model A Ford \u0026amp; parked it in the front yard. We were in the living room talking when another Model A Ford drove up \u0026amp; in it were my sister \u0026amp; a friend of mine. I went out in the front yard, got in this couple\u0026#39;s car, and started to talk to my sister. D___ my sister, asked me if I wanted to go to a play with J. She said that she and her husband weren\u0026#39;t going. I realized that I would have to go with him alone, so I refused. Then they drove away and the wife came out in the yard. She seemed perturbed at my getting into their car, so she got into the car and backed it away. The car then suddenly changed into an old-fashioned bicycle. It was at this time that I felt antagonistic towards this couple.\u0026quot; So the pattern here seems to be that underscores are used to disguise the identity of named people in the dreams. We can choose to filter these out as they are not relevant to our analysis. But before we do this filtering, let’s also consider the numbers in the word variable column - again in a bag-of-words approach one could argue that these are not words and so are irrelevant. We want to create a pattern that identifies both digits and underscores, and then use a function to transform our word variable in the df_word dataframe.\n Create pattern to remove numbers and underscores We can use the function str_subset() to identify the elements of the word variable that we wish to remove. Let’s create a pattern that deals initially with the underscores and try str_subset() with it. The ‘+’ is not strictly necessary here, but it illustrates that we can identify at least one underscore by this combination.\nstr_subset(df_word$word, pattern = \u0026#39;_+\u0026#39;) ## [1] \u0026quot;n__\u0026quot; \u0026quot;y__\u0026quot; \u0026quot;c___\u0026quot; \u0026quot;___\u0026quot; \u0026quot;d___\u0026quot; \u0026quot;h___\u0026quot; \u0026quot;a___\u0026quot; \u0026quot;a___\u0026quot; ## [9] \u0026quot;h__\u0026quot; \u0026quot;______\u0026quot; This has found ten instances of the underscore in the word variable. Now we want to find all the digits. We could use the regex shorthand [\\d] or [:digit:]. Let’s use the latter first with str_subset to check it works.\nstr_subset(df_word$word, pattern = \u0026#39;[:digit:]\u0026#39;) ## [1] \u0026quot;169\u0026quot; \u0026quot;80\u0026quot; \u0026quot;90\u0026quot; \u0026quot;30\u0026quot; \u0026quot;60\u0026quot; \u0026quot;40\u0026quot; \u0026quot;45\u0026quot; \u0026quot;4\u0026quot; ## [9] \u0026quot;20\u0026quot; \u0026quot;4\u0026quot; \u0026quot;5\u0026quot; \u0026quot;2\u0026quot; \u0026quot;34\u0026quot; \u0026quot;34\u0026quot; \u0026quot;309\u0026quot; \u0026quot;219\u0026quot; ## [17] \u0026quot;6\u0026quot; \u0026quot;5.00\u0026quot; \u0026quot;8\u0026quot; \u0026quot;5\u0026quot; \u0026quot;45\u0026quot; \u0026quot;20\u0026quot; \u0026quot;45\u0026quot; \u0026quot;22\u0026quot; ## [25] \u0026quot;50\u0026quot; \u0026quot;23\u0026quot; \u0026quot;45\u0026quot; \u0026quot;22\u0026quot; \u0026quot;30\u0026quot; \u0026quot;45\u0026quot; \u0026quot;22\u0026quot; \u0026quot;11\u0026quot; ## [33] \u0026quot;8\u0026quot; \u0026quot;8\u0026quot; \u0026quot;12\u0026quot; \u0026quot;3rd\u0026quot; \u0026quot;26\u0026quot; \u0026quot;20\u0026quot; \u0026quot;20\u0026quot; \u0026quot;22\u0026quot; ## [41] \u0026quot;60\u0026quot; \u0026quot;70\u0026quot; \u0026quot;20\u0026quot; \u0026quot;25\u0026quot; \u0026quot;20\u0026quot; \u0026quot;27\u0026quot; \u0026quot;23\u0026quot; \u0026quot;52\u0026quot; ## [49] \u0026quot;23\u0026quot; \u0026quot;7\u0026quot; \u0026quot;30\u0026quot; \u0026quot;2nd\u0026quot; \u0026quot;2nd\u0026quot; \u0026quot;7\u0026quot; \u0026quot;10\u0026quot; \u0026quot;10\u0026quot; ## [57] \u0026quot;2\u0026quot; \u0026quot;1\u0026quot; \u0026quot;1\u0026quot; \u0026quot;2\u0026quot; \u0026quot;999\u0026quot; \u0026quot;e1\u0026quot; \u0026quot;10\u0026quot; \u0026quot;2\u0026quot; ## [65] \u0026quot;4\u0026quot; \u0026quot;2\u0026quot; \u0026quot;2\u0026quot; \u0026quot;2\u0026quot; \u0026quot;25\u0026quot; \u0026quot;20\u0026quot; \u0026quot;5\u0026quot; \u0026quot;22\u0026quot; ## [73] \u0026quot;20\u0026quot; \u0026quot;8\u0026quot; \u0026quot;30\u0026quot; \u0026quot;6\u0026quot; \u0026quot;8\u0026quot; \u0026quot;30\u0026quot; \u0026quot;8\u0026quot; \u0026quot;30\u0026quot; ## [81] \u0026quot;50\u0026quot; \u0026quot;4\u0026quot; \u0026quot;35\u0026quot; \u0026quot;4\u0026quot; \u0026quot;00\u0026quot; \u0026quot;40\u0026quot; \u0026quot;20\u0026quot; \u0026quot;5\u0026quot; ## [89] \u0026quot;10\u0026quot; \u0026quot;2\u0026quot; \u0026quot;80\u0026quot; \u0026quot;45\u0026quot; \u0026quot;48\u0026quot; \u0026quot;55\u0026quot; \u0026quot;22\u0026quot; \u0026quot;40\u0026quot; ## [97] \u0026quot;1992\u0026quot; \u0026quot;200\u0026quot; \u0026quot;300\u0026quot; \u0026quot;100\u0026quot; \u0026quot;20s\u0026quot; \u0026quot;30s\u0026quot; \u0026quot;1950s\u0026quot; \u0026quot;2001\u0026quot; ## [105] \u0026quot;2012\u0026quot; \u0026quot;10\u0026quot; \u0026quot;12\u0026quot; \u0026quot;1990s\u0026quot; \u0026quot;50s\u0026quot; \u0026quot;1972\u0026quot; \u0026quot;1950s\u0026quot; \u0026quot;800\u0026quot; ## [113] \u0026quot;45\u0026quot; \u0026quot;60s\u0026quot; \u0026quot;1970\u0026quot; \u0026quot;45\u0026quot; \u0026quot;1960s\u0026quot; \u0026quot;105\u0026quot; \u0026quot;1st\u0026quot; \u0026quot;109\u0026quot; ## [121] \u0026quot;110\u0026quot; \u0026quot;116\u0026quot; \u0026quot;121\u0026quot; \u0026quot;122\u0026quot; \u0026quot;2001\u0026quot; \u0026quot;2012\u0026quot; \u0026quot;138\u0026quot; \u0026quot;139\u0026quot; ## [129] \u0026quot;152\u0026quot; \u0026quot;m16\u0026quot; \u0026quot;m60\u0026quot; \u0026quot;59\u0026quot; \u0026quot;2001\u0026quot; \u0026quot;2012\u0026quot; \u0026quot;39\u0026quot; \u0026quot;244\u0026quot; ## [137] \u0026quot;1200\u0026quot; \u0026quot;207\u0026quot; \u0026quot;208\u0026quot; \u0026quot;209\u0026quot; \u0026quot;211\u0026quot; \u0026quot;214\u0026quot; \u0026quot;215\u0026quot; \u0026quot;216\u0026quot; ## [145] \u0026quot;800\u0026quot; \u0026quot;411\u0026quot; \u0026quot;42nd\u0026quot; \u0026quot;217\u0026quot; \u0026quot;218\u0026quot; \u0026quot;219\u0026quot; \u0026quot;2am\u0026quot; \u0026quot;123\u0026quot; ## [153] \u0026quot;220\u0026quot; \u0026quot;1950s\u0026quot; \u0026quot;2\u0026quot; \u0026quot;20\u0026quot; \u0026quot;20\u0026quot; \u0026quot;19\u0026quot; \u0026quot;20\u0026quot; \u0026quot;22\u0026quot; ## [161] \u0026quot;8\u0026quot; \u0026quot;27\u0026quot; \u0026quot;3\u0026quot; \u0026quot;1,500\u0026quot; \u0026quot;50\u0026quot; \u0026quot;17\u0026quot; \u0026quot;26\u0026quot; \u0026quot;30\u0026quot; ## [169] \u0026quot;10\u0026quot; \u0026quot;70\u0026quot; \u0026quot;6\u0026quot; \u0026quot;3\u0026quot; \u0026quot;4\u0026quot; \u0026quot;30\u0026quot; \u0026quot;33\u0026quot; \u0026quot;45\u0026quot; ## [177] \u0026quot;4\u0026quot; \u0026quot;12\u0026quot; \u0026quot;12\u0026quot; \u0026quot;160\u0026quot; \u0026quot;10\u0026quot; \u0026quot;11\u0026quot; \u0026quot;85\u0026quot; \u0026quot;22\u0026quot; ## [185] \u0026quot;11\u0026quot; \u0026quot;10\u0026quot; \u0026quot;50\u0026quot; \u0026quot;300\u0026quot; \u0026quot;30\u0026quot; \u0026quot;10\u0026quot; \u0026quot;20\u0026quot; \u0026quot;440\u0026quot; ## [193] \u0026quot;880\u0026quot; \u0026quot;10\u0026quot; \u0026quot;20\u0026quot; \u0026quot;30\u0026quot; \u0026quot;3000\u0026quot; \u0026quot;3\u0026quot; \u0026quot;3\u0026quot; \u0026quot;3\u0026quot; ## [201] \u0026quot;11\u0026quot; \u0026quot;12\u0026quot; \u0026quot;12\u0026quot; \u0026quot;2\u0026quot; \u0026quot;13\u0026quot; \u0026quot;26\u0026quot; \u0026quot;8\u0026quot; \u0026quot;30\u0026quot; ## [209] \u0026quot;11\u0026quot; \u0026quot;30\u0026quot; \u0026quot;19\u0026quot; \u0026quot;7\u0026quot; \u0026quot;30\u0026quot; \u0026quot;8\u0026quot; \u0026quot;30\u0026quot; \u0026quot;28\u0026quot; ## [217] \u0026quot;50\u0026quot; \u0026quot;30\u0026quot; \u0026quot;18\u0026quot; \u0026quot;18\u0026quot; \u0026quot;15\u0026quot; \u0026quot;20\u0026quot; \u0026quot;21\u0026quot; \u0026quot;20\u0026quot; ## [225] \u0026quot;6\u0026quot; \u0026quot;30\u0026quot; \u0026quot;19\u0026quot; \u0026quot;16\u0026quot; \u0026quot;2\u0026quot; \u0026quot;23\u0026quot; \u0026quot;25\u0026quot; \u0026quot;35\u0026quot; ## [233] \u0026quot;40\u0026quot; \u0026quot;25\u0026quot; \u0026quot;5\u0026quot; \u0026quot;3\u0026quot; \u0026quot;2\u0026quot; \u0026quot;23\u0026quot; \u0026quot;50\u0026quot; \u0026quot;3\u0026quot; ## [241] \u0026quot;3\u0026quot; \u0026quot;1\u0026quot; \u0026quot;2\u0026quot; \u0026quot;2\u0026quot; \u0026quot;23\u0026quot; \u0026quot;40\u0026quot; \u0026quot;35\u0026quot; \u0026quot;8\u0026quot; ## [249] \u0026quot;8\u0026quot; \u0026quot;2\u0026quot; \u0026quot;107th\u0026quot; \u0026quot;16\u0026quot; \u0026quot;27\u0026quot; \u0026quot;10\u0026quot; \u0026quot;8\u0026quot; \u0026quot;60\u0026quot; ## [257] \u0026quot;21\u0026quot; \u0026quot;20\u0026quot; \u0026quot;50\u0026quot; \u0026quot;2\u0026quot; \u0026quot;11\u0026quot; \u0026quot;15\u0026quot; \u0026quot;11\u0026quot; \u0026quot;17\u0026quot; ## [265] \u0026quot;17\u0026quot; \u0026quot;2\u0026quot; \u0026quot;34\u0026quot; \u0026quot;45\u0026quot; \u0026quot;49\u0026quot; \u0026quot;52\u0026quot; \u0026quot;55\u0026quot; \u0026quot;3\u0026quot; ## [273] \u0026quot;5\u0026quot; \u0026quot;20\u0026quot; \u0026quot;26\u0026quot; \u0026quot;75.00\u0026quot; \u0026quot;2\u0026quot; \u0026quot;6\u0026quot; \u0026quot;27\u0026quot; \u0026quot;3\u0026quot; ## [281] \u0026quot;4\u0026quot; \u0026quot;00\u0026quot; \u0026quot;1st\u0026quot; \u0026quot;2nd\u0026quot; \u0026quot;3rd\u0026quot; \u0026quot;10\u0026quot; \u0026quot;20\u0026quot; \u0026quot;10\u0026quot; ## [289] \u0026quot;30\u0026quot; \u0026quot;50\u0026quot; \u0026quot;50\u0026quot; \u0026quot;11,000\u0026quot; \u0026quot;1\u0026quot; \u0026quot;48th\u0026quot; \u0026quot;4\u0026quot; \u0026quot;6\u0026quot; ## [297] \u0026quot;25th\u0026quot; \u0026quot;100\u0026quot; \u0026quot;100\u0026quot; This works very nicely as well. However, to use these patterns with the tidyverse pipe, it is easier to use the fitler() function rather than str_subset(), and since it is convenient to chain steps in the pipe, we can use two calls to filter(), first by underscores and secondly by digits. And as we don’t want either of these in our dataset, we will set the “negate” argument to TRUE in both cases. An alternative method to delete the digits would be to use the capital “D” in the regex, but this way keeps our filters more uniform, both with a “negate = TRUE” argument.\ndf_word %\u0026gt;% filter(str_detect(word, pattern = \u0026quot;_\u0026quot;, negate = TRUE)) %\u0026gt;% filter(str_detect(word, pattern = \u0026#39;[\\\\d]\u0026#39;, negate = TRUE)) ## # A tibble: 17,953 x 3 ## sample dream_number word ## \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; ## 1 college_women 1 dreamed ## 2 college_women 1 office ## 3 college_women 1 directress ## 4 college_women 1 nurses ## 5 college_women 1 nursing ## 6 college_women 1 school ## 7 college_women 1 forty ## 8 college_women 1 told ## 9 college_women 1 results ## 10 college_women 1 i.q ## # … with 17,943 more rows  Plot word frequencies Now we have done some tidying on the dataset, we can plot the word frequencies - a simple way is to pass them through a filter so we only retain those words with a frequency greater than say n = 60. Notice we use mutate to create the new variables for the plot word (in the order of frequency) and n. We then filter by frequency, and pass the two new variables to the ggplot function. We also have to switch syntax at this point from the pipe ( %\u0026gt;% ) to the + sign between the layers of the ggplot() function. We flip the coordinates, as it allows us to keep the words in the horizontal aspect and makes it the plot easier to read.\ndf_word %\u0026gt;% count(word, sort = TRUE) %\u0026gt;% mutate(word = reorder(word, n)) %\u0026gt;% filter(n \u0026gt; 60) %\u0026gt;% ggplot(aes(x = word, y = n)) + geom_col()+ coord_flip() This gives us an overview of the most commonly used words in dreams recalled by all four samples. But it would be more interesting to see how the word use differs between the samples. However, we should be prepared for the possibility that the length of dreams may vary between samples. To control for this, we might want to convert our raw counts of words to proportions from the dream text. Let’s check for the variety of dream lengths by using str_count() function on our original dataset df - hence before we removed our stopwords. We will count the words in each dream and store the result in a vector called dream_lengths. The default for str_count is for the function to count characters if no pattern is given to match. However, if we pass it a second argument, specifying the regex for all sequences of non-space characters, it will count words instead. The regex includes the code for any non-white space character ‘\\S’, with the addition of ‘+’ sign to indicate one or more non-white space characters, and the initial escape character ‘\\’ as ‘\\S’ is not recognised as an escape character without it.\ndream_lengths \u0026lt;- str_count(df$dream, \u0026quot;\\\\S+\u0026quot;) plot(dream_lengths, xlab = \u0026quot;Dream Number\u0026quot;) This is a good example of the use of the plot() function with a single vector in R. The default behaviour is to plot the values of the vector against the y-axis - dream_lengths in this case, and then use the index number (ie. the order in which each value occurs in the vector) as the x value. So our x-axis simple represents the order of the dreams, or as we have named this, the dream number. We can see here the range of dream lengths with the minimum being about 35 words and the maximum around 290 words. We could take the min, max, mean and SD if we wanted to be more specific.\nmin(dream_lengths); max(dream_lengths); mean(dream_lengths); sd(dream_lengths) ## [1] 38 ## [1] 288 ## [1] 141.0325 ## [1] 45.09413 There is a great deal of variability in the dream lengths, so proportions will be better than raw counts to represent the frequency of each word.\n Calculating word frequencies as proportions We will want to count proportions after stopwords are removed. We have a choice here whether we want to express the frequency of individual words by proportion of a dream or proportion of a sample. These would have different interpretations. If the texts (in our case dreams) were much longer, proportion by text might be the better way to represent the data, but I suspect proportion by dream may not be very informative. Let’s try it and see what the results look like. We will group_by() dream_number so as to create proportion by dream. Then we use a summarise function to create a word count, and we use mutate to convert this to percentage. I used a second mutate to clean this up into two decimal places with the round() function. Finally, we use the tidyverse equivalent of sort() which is the arrange() function - but because we want this to be largest-to-smallest, we also include the desc() descending function.\ndf_word %\u0026gt;% group_by(dream_number, word) %\u0026gt;% summarise(n = n()) %\u0026gt;% mutate(percent = (n / sum(n))*100) %\u0026gt;% mutate(percent = round(percent, 2)) %\u0026gt;% arrange(desc(percent)) %\u0026gt;% ungroup ## # A tibble: 15,500 x 4 ## dream_number word n percent ## \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; ## 1 6 remember 3 21.4 ## 2 358 office 5 20 ## 3 355 dog 7 19.4 ## 4 381 bus 6 18.2 ## 5 2 hair 3 16.7 ## 6 20 bed 3 16.7 ## 7 83 store 5 16.7 ## 8 260 car 6 16.7 ## 9 399 test 6 15.8 ## 10 13 dream 2 15.4 ## # … with 15,490 more rows So in dream number 6 the word ‘remember’ accounted for 21% of the non-stopwords used. That seems like a high proportion. It might be more useful to look at the data aggregated across samples. We can change the code to group_by sample instead of dream_number, then recalculate the most frequently occurring words as a proportion of words by sample.\ndf_word %\u0026gt;% group_by(sample, word) %\u0026gt;% summarise(n = n()) %\u0026gt;% mutate(percent = (n / sum(n))*100) %\u0026gt;% mutate(percent = round(percent, 2)) %\u0026gt;% arrange(desc(percent)) %\u0026gt;% ungroup() ## # A tibble: 8,118 x 4 ## sample word n percent ## \u0026lt;fct\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; ## 1 college_women remember 55 1.63 ## 2 hall_male dream 57 1.31 ## 3 hall_male car 51 1.17 ## 4 hall_male house 49 1.13 ## 5 vietnam_vet woman 64 1 ## 6 hall_female remember 40 0.96 ## 7 college_women car 32 0.95 ## 8 college_women dream 32 0.95 ## 9 hall_female dream 38 0.92 ## 10 hall_female house 36 0.87 ## # … with 8,108 more rows We can see that for the college women, the word ‘remember’ features the most frequently across the whole sample of 100 dreams and makes up roughly 1.6% of the non-stopwords in the dreams recorded.\n Conclusion We have explored how to tokenise texts, do some basic text cleaning and creating counts and proportions and finally graphed the simple word counts. In the next post in this series, I will explore the dream data using a clever technique from Julia Silge and David Robinson’s book that involves the spread() and gather() functions.\n ","date":1578960000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578996737,"objectID":"19340cf6874e1da6ce7318aeff91e1d5","permalink":"/post/manipulating-text-data-from-dreams/","publishdate":"2020-01-14T00:00:00Z","relpermalink":"/post/manipulating-text-data-from-dreams/","section":"post","summary":"In the previous post on ‘pulling text data from the internet’, I experimented with pulling out the dream text from a sample of dreams from the website “DreamBank” at: http://www.dreambank.net/random_sample.cgi.\nIn this follow-up post, I will demonstrate some of the methods presented in Julia Silge and David Robinson’s book ‘Text Mining with R’ for processing text data, as applied to 400 dreams sampled from 4 collections in the dreambank. I used the methods described in the last post to pull out a random sample of 100 dreams from each of the following 4 groups:","tags":["Text mining"],"title":"Manipulating text data from dreams","type":"post"},{"authors":[],"categories":["R coding"],"content":" I have been working on the area of alexithymia for the last couple of years, a sub-clinical condition in which people find it difficult to identify and describe their emotions. I am currently analysing a dataset containing transcripts of interviews with people with and without alexithymia and I wanted to try out some R tools for text analysis. However, to do a blog post I needed some public data, and while mulling over what data I might use, I stumbled upon a line in “You are a thing and I love you” - the wonderful new book on AI by Janelle Shane.\nhttps://www.amazon.com/You-Look-Like-Thing-Love/dp/0316525243\nShe mentions training an AI on a dream dataset available at dreamreasearch.net. The website has section called “DreamBank” that allows you to search or take random samples of dreams recorded from a variety of sources. Under the Random Sample link, at: http://www.dreambank.net/random_sample.cgi one can select a dream source.\n We will need a few packages for this process - rvest is useful for pulling data from online sources. The two text packages stringr and stringi offer a range of tools for managing text data. The tidyverse will simplify the management of the dataset and knitr is useful for managing the display of text in Rmarkdown documents.\nlibrary(rvest) library(stringr) library(stringi) library(tidyverse) library(knitr) Let’s start by taking a look at the dreams of college women from the 1940’s. We set an address for the url, then pass this as an argument to the read_html() function.\nurl \u0026lt;- \u0026quot;http://www.dreambank.net/random_sample.cgi?series=hall_female\u0026amp;min=100\u0026amp;max=300\u0026amp;n=100\u0026quot; page \u0026lt;- read_html(url) I followed the guidance in Kwartler (‘Text Mining in Practice with R’, 2017) and checked the field with the dream text on the webpage in Chrome using the SelectorGadget plugin. This revealed that these text fields were labelled as “span”. So we can include this as the type of node to select in the html_node() function from rvest. This allows us to pull the html text from just these fields and store them in a new variable called posts, then I will convert this html_text to raw text and store it in a variable called dream. I suppose I could have wrapped the html_nodes call within the html_text function and skipped creating an intermediate variable (posts), but I think it makes the code more readable this way.\nposts \u0026lt;- html_nodes(page, \u0026#39;span\u0026#39;) dream \u0026lt;- html_text(posts) We can convert this to a dataframe - we will use the tidyverse version, a tibble, as this will avoid problems of the dreams being converted to factors. For more on why this can be problematic, read “stringsAsFactors: An unauthorized biography” by Roger Peng at this site:\nhttps://simplystatistics.org/2015/07/24/stringsasfactors-an-unauthorized-biography/\ndf \u0026lt;- tibble(dream = dream) As a side-note, we could have done each of these steps with a more tidyverse syntax, by using the pipe, though this may have meant that each of the substeps was less transparent. We could have taken the pages object that contains our raw data and piped it through the various functions to extract just the dreams, then converted it into a tibble. As we haven’t declared a name for the one variable in the tibble, we need to use the rename function to assign the name ‘dream’ to the column.\ndf \u0026lt;- page %\u0026gt;% html_nodes(\u0026#39;span\u0026#39;) %\u0026gt;% html_text() %\u0026gt;% tibble() %\u0026gt;% rename(\u0026#39;dream\u0026#39; = \u0026#39;.\u0026#39;) Let’s take a quick peak at the data. We can create a quick function to truncate the display of the dreams to 60 characters. We will call this function custom_view(). We will restrict the view to just the first 5 rows as well, using indexing.\ncustom_view \u0026lt;- function(x) data.frame(lapply(x, substr, 1, 60)) custom_view(df[1:5,]) ## dream ## 1 \\n#0001 (Code 001, Age 24, 11/??/47)I dreamed that I was at a ## 2 \\n#0008 (Code 001, Age 24, 11/??/47)I dreamed that I went to ## 3 \\n#0025 (Code 007, Age 20, 03/20/48)As I first remember the d ## 4 \\n#0028 (Code 007, Age 20, 04/09/48)I was at a factory workin ## 5 \\n#0036 (Code 008, Age 22, 02/25/48)I was in a house. It was Currently, our dataset has just one column and we will need to fix this. Let’s use substr to pull out the dream number that occurs at the beginning of the text field. The substr() function takes three arguments, the vector, character start and character stop.\nFor example, this is what we get if we pull out the three numeric identifier characters (start at 4 and stop at 6).\nsubstr(df$dream, 4, 6) ## [1] \u0026quot;001\u0026quot; \u0026quot;008\u0026quot; \u0026quot;025\u0026quot; \u0026quot;028\u0026quot; \u0026quot;036\u0026quot; \u0026quot;038\u0026quot; \u0026quot;049\u0026quot; \u0026quot;050\u0026quot; \u0026quot;051\u0026quot; \u0026quot;055\u0026quot; \u0026quot;059\u0026quot; \u0026quot;065\u0026quot; ## [13] \u0026quot;074\u0026quot; \u0026quot;081\u0026quot; \u0026quot;084\u0026quot; \u0026quot;087\u0026quot; \u0026quot;098\u0026quot; \u0026quot;101\u0026quot; \u0026quot;117\u0026quot; \u0026quot;123\u0026quot; \u0026quot;137\u0026quot; \u0026quot;156\u0026quot; \u0026quot;163\u0026quot; \u0026quot;164\u0026quot; ## [25] \u0026quot;165\u0026quot; \u0026quot;186\u0026quot; \u0026quot;190\u0026quot; \u0026quot;221\u0026quot; \u0026quot;223\u0026quot; \u0026quot;225\u0026quot; \u0026quot;226\u0026quot; \u0026quot;230\u0026quot; \u0026quot;232\u0026quot; \u0026quot;251\u0026quot; \u0026quot;261\u0026quot; \u0026quot;271\u0026quot; ## [37] \u0026quot;278\u0026quot; \u0026quot;290\u0026quot; \u0026quot;292\u0026quot; \u0026quot;296\u0026quot; \u0026quot;301\u0026quot; \u0026quot;302\u0026quot; \u0026quot;304\u0026quot; \u0026quot;309\u0026quot; \u0026quot;310\u0026quot; \u0026quot;313\u0026quot; \u0026quot;335\u0026quot; \u0026quot;351\u0026quot; ## [49] \u0026quot;352\u0026quot; \u0026quot;353\u0026quot; \u0026quot;356\u0026quot; \u0026quot;360\u0026quot; \u0026quot;361\u0026quot; \u0026quot;367\u0026quot; \u0026quot;368\u0026quot; \u0026quot;371\u0026quot; \u0026quot;373\u0026quot; \u0026quot;383\u0026quot; \u0026quot;384\u0026quot; \u0026quot;396\u0026quot; ## [61] \u0026quot;402\u0026quot; \u0026quot;404\u0026quot; \u0026quot;405\u0026quot; \u0026quot;406\u0026quot; \u0026quot;408\u0026quot; \u0026quot;415\u0026quot; \u0026quot;435\u0026quot; \u0026quot;440\u0026quot; \u0026quot;460\u0026quot; \u0026quot;468\u0026quot; \u0026quot;475\u0026quot; \u0026quot;483\u0026quot; ## [73] \u0026quot;491\u0026quot; \u0026quot;499\u0026quot; \u0026quot;503\u0026quot; \u0026quot;506\u0026quot; \u0026quot;528\u0026quot; \u0026quot;530\u0026quot; \u0026quot;537\u0026quot; \u0026quot;540\u0026quot; \u0026quot;543\u0026quot; \u0026quot;547\u0026quot; \u0026quot;550\u0026quot; \u0026quot;556\u0026quot; ## [85] \u0026quot;563\u0026quot; \u0026quot;582\u0026quot; \u0026quot;586\u0026quot; \u0026quot;606\u0026quot; \u0026quot;609\u0026quot; \u0026quot;616\u0026quot; \u0026quot;620\u0026quot; \u0026quot;629\u0026quot; \u0026quot;641\u0026quot; \u0026quot;652\u0026quot; \u0026quot;659\u0026quot; \u0026quot;660\u0026quot; ## [97] \u0026quot;664\u0026quot; \u0026quot;666\u0026quot; \u0026quot;667\u0026quot; \u0026quot;681\u0026quot; This worked fine, so let’s create a new variable called code to store this data in our dataframe. This will be our id code for each dream.\ndf$code \u0026lt;- substr(df$dream, 4, 6) The column with the code should come first, so we will swap the order of columns with a simple index call - concatenating the order of variables, passed as the second argument.\ndf \u0026lt;- df[,c(2,1)] After examining the dataframe, we can see that the pattern for ages is given by the word ‘Age’ with a capital ‘A’, followed by a space, then the actual age as two digits, like this: “Age 24”. We can create a regex pattern to match this and use the stringr package to extract this string and store it in a vector called age.\nage \u0026lt;- str_extract(df$dream, \u0026quot;[A][g][e][ ][0-9]{2}\u0026quot;) However, if we want to manipulate the ages as integers, we need to extract just the number and coerce it from a character vector into a numeric vector. We can do this with another regex, which just pulls out the two digits. And let’s convert it into a numeric and paste the data back into the dataframe, and move it to the second column.\nage_refined \u0026lt;- str_extract(age, \u0026quot;([0-9]{2})\u0026quot;) df$age \u0026lt;- as.numeric(age_refined) df \u0026lt;- df[,c(1,3,2)] Now we want to tidy up the dream variable. At the moment we have a bunch of characters before the dream itself starts. We can experiment with the str_locate function and a regex to see if we can identify the pattern for where the dream begins. Let’s try the closing brace which seems to come after the date of the dream.\nhead(str_locate(df$dream, \u0026quot;[)]\u0026quot;)) ## start end ## [1,] 35 35 ## [2,] 35 35 ## [3,] 35 35 ## [4,] 35 35 ## [5,] 35 35 ## [6,] 35 35 This indicates that a closing brace always occurs at the 35th character in the dream text field. We can use the Base R function substr() which takes a vector, a start and an end point. We know the start (character 36), which is the first character after the closing brace of the date, but we don’t know the end, as all the dreams are different lenghts. But we can use the handy nchar() function which counts the number of characters for us, so we treat this as a flexible endpoint. As this seems to work nicely, let’s overwrite our dream variable with this new version\ndf$dream \u0026lt;- substr(df$dream, 36, nchar(df$dream)) A quick look at the df using our custom_view() function indictes this is shaping up nicely.\ncustom_view(df)[1:5,] ## code age dream ## 1 001 24 I dreamed that I was at a public affair but I don\u0026#39;t know whi ## 2 008 24 I dreamed that I went to take an examination and I was late ## 3 025 20 As I first remember the dream I was upstairs in a room with ## 4 028 20 I was at a factory working. I saw a college girl-friend of m ## 5 036 22 I was in a house. It was a beautiful large home with expensi But what about the end of each dream? Let’s examine the first dream in detail.\n## [1] \u0026quot;I dreamed that I was at a public affair but I don\u0026#39;t know which affair\u0026quot; ## [2] \u0026quot;it was although it was outdoors. There were many people around us and\u0026quot; ## [3] \u0026quot;they were of all ages. I was at this affair with B. He is about\u0026quot; ## [4] \u0026quot;twenty-six years old and he is the boy-friend of one of the girls\u0026quot; ## [5] \u0026quot;that lives in the dormitory that I do. Whenever I felt the urge to\u0026quot; ## [6] \u0026quot;get away from my escort or from the people at the affair, I would\u0026quot; ## [7] \u0026quot;start to fly. (like superman). While up in the air I felt very uneasy\u0026quot; ## [8] \u0026quot;and worried about how I would get back down without hurting myself. I\u0026quot; ## [9] \u0026quot;left my escort about three times in this way. I do not remember why I\u0026quot; ## [10] \u0026quot;felt that I had to get away. Interpretation I do not know why I would\u0026quot; ## [11] \u0026quot;dream of B. I do not know him very well and I do not feel very\u0026quot; ## [12] \u0026quot;friendly toward him when I do see him. I believe that I associated\u0026quot; ## [13] \u0026quot;him with my studies and felt that I had to get away for a short\u0026quot; ## [14] \u0026quot;while. When I had this dream, I hadn\u0026#39;t been home for about eight\u0026quot; ## [15] \u0026quot;weeks and was looking forward to going home. I felt that I wanted a\u0026quot; ## [16] \u0026quot;short vacation from my studies and this dream was an escape mechanism\u0026quot; ## [17] \u0026quot;in the form of a fantasy to get away from my classes for a short\u0026quot; ## [18] \u0026quot;while. Answers to questions 2. Frustrated. I felt that I had to get\u0026quot; ## [19] \u0026quot;away.3. actual participant4. unpleasant5. Vague, but it was\u0026quot; ## [20] \u0026quot;outdoors.6. No.7. No. (268 words)\u0026quot; We can see that each dream includes an interpretation and I only want to analyse the dream narrative itself, not the person’s reflections on the meaning of the dream. We can use the word ‘Interpretation’ to identify the end point of the dream narrative. We can just pull out the first 6 values by wrapping this in the head function.\nhead(str_locate(df$dream, \u0026quot;Interpretation\u0026quot;)) ## start end ## [1,] 643 656 ## [2,] 722 735 ## [3,] 642 655 ## [4,] 306 319 ## [5,] 415 428 ## [6,] 327 340 We still need to do a bit of work - the str_locate() returns two values and we only want the first one. Secondly, when we trim the text, we want to start two characters to the left as we don’t want the first letter of the word “Interpretation”, or the whitespace just before it. We can store the location in a new vector called loc - then we can take out the start point only, with the index [,1]. On the third line we will crop the text to start at 0 and end at 2 characters to the left (-2) of the start point. We reassign it to the same variable in our dataframe - df$dream.\nloc \u0026lt;- str_locate(df$dream, \u0026quot;Interpretation\u0026quot;) start \u0026lt;- loc[,1] # take out start point [,1] as a vector called start df$dream \u0026lt;- substr(df$dream, 0, start-2)  Finally, let’s check that the changes worked by examining the final 70 characters of the first dream.\n## [1] \u0026quot;is way. I do not remember why I felt that I had to get away.\u0026quot; This is just what we wanted - this is line 9 and 10 of the full dream we examined up above - finishing just before the interpretation starts.\nIn the next post, I will pull in the dreams from three other samples and start to look at the sentiment analysis of the dream content.\n","date":1575072000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575106735,"objectID":"ab74018af8115168356b28a056f02627","permalink":"/post/pulling-text-data-from-the-internet/","publishdate":"2019-11-30T00:00:00Z","relpermalink":"/post/pulling-text-data-from-the-internet/","section":"post","summary":"I have been working on the area of alexithymia for the last couple of years, a sub-clinical condition in which people find it difficult to identify and describe their emotions. I am currently analysing a dataset containing transcripts of interviews with people with and without alexithymia and I wanted to try out some R tools for text analysis. However, to do a blog post I needed some public data, and while mulling over what data I might use, I stumbled upon a line in “You are a thing and I love you” - the wonderful new book on AI by Janelle Shane.","tags":["R"],"title":"Pulling text data from the internet","type":"post"},{"authors":[],"categories":["R coding"],"content":" Recently, while trying to compare the distribution of two samples, I discovered that you can plot both on the same graph in base R, which is a nice feature if you just want to examine the data quickly. We can explore this with a psychological dataset from the Open Psychometrics site. This hosts a range of open psychometric tests and stores the data in an accessible form. Let’s pull out the data for the Rosenberg Self-Esteem Scale (note that there are two different scoring methods in common use on this scale - on the website they have used a 1 - 4 Likert scale for the data output as a csv, but it is not unusual to see the use of a 0 - 3 scale, (which is the method used to give participants on the website feedback) so we need to be cautious when comparing these total scores with published norms (see https://socy.umd.edu/about-us/using-rosenberg-self-esteem-scale)).\nFirst we will load two packages we are going to use. We want the tidyverse for manipulating the variables and we will use the psych package for creating total scores on the measure itself.\nlibrary(tidyverse) library(psych) Next we want to set an url object to direct the download.file() to the right place to pull the data. I have called it my_url for simplicity. We pass this as the first argument in the download.file() function. We then set a destination for the file to be saved with the dest argument. Finally we use unzip to unpack the zipped file.\nmy_url \u0026lt;- \u0026quot;http://openpsychometrics.org/_rawdata/RSE.zip\u0026quot; download.file(url = my_url, dest=\u0026quot;data.zip\u0026quot;, mode=\u0026quot;wb\u0026quot;) unzip (\u0026quot;data.zip\u0026quot;, exdir = \u0026quot;./\u0026quot;) Now we can import the data with the read_tsv() function. We can’t use the read_csv() function with the data, because despite having a .csv extension, the data is actually tab-separated not comma-separated.\ndf \u0026lt;- read_tsv(\u0026quot;RSE/data.csv\u0026quot;) In the Rosenberg Self-Esteem scale Items 2, 5, 6, 8, 9 are normally reverse scored. However, whoever loaded the questions on the website put them in a different order, with items 3, 5, 8, 9, 10 needing reversing. We need to create a total score for the measure and to be mindful of the reverse coded items. The psych package provides a function for this called scoreFast. We need to pass it a list called keys.list which specifies the direction of each item in turn (items are scored as-is if they have no leading ‘-’ minus sign, but all items with a minus are reverse scored). We won’t bother recoding the data from the 1 - 4 scale to 0 - 3 as it makes little difference for your graphs.\nkeys.list \u0026lt;- list(c(\u0026#39;Q1\u0026#39;, \u0026#39;Q2\u0026#39;, \u0026#39;-Q3\u0026#39;, \u0026#39;Q4\u0026#39;, \u0026#39;-Q5\u0026#39;, \u0026#39;Q6\u0026#39;, \u0026#39;Q7\u0026#39;, \u0026#39;-Q8\u0026#39;, \u0026#39;-Q9\u0026#39;, \u0026#39;-Q10\u0026#39;)) df$total \u0026lt;- scoreFast(keys.list, items = df[1:10], totals = TRUE, min = 1, max = 4) Now we have our dataset, we can look at comparing distributions. We might want to know if the distribution of self-esteem scores differs between men and women. Checking the codebook on the website, we can see that males are coded as ‘1’ and females as ‘2’.\nmen \u0026lt;- df %\u0026gt;% filter(gender == 1) women \u0026lt;- df %\u0026gt;% filter(gender == 2) So let’s plot the total self-esteem scores for the women in the sample as a simple histogram.\nhist(women$total) We can see a fairly normal distribution of scores. We can check the mean, but we might predict it is around 25.\nmean(women$total) ## [1] 25.74368 Next we can add the men’s scores to the same plot. Here we simply create the first plot, then make a second plot with the argument add set to TRUE. We will set the density to 35 so we can see throught the bars on the histogram.\nhist(women$total, col = \u0026#39;red\u0026#39;, main = \u0026quot;Histogram of Total scores on Rosenberg Self-Esteem Scale\u0026quot;, xlab = \u0026quot;Total score\u0026quot;) hist(men$total, add = TRUE, col = \u0026#39;blue\u0026#39;, density = 35) I have used the pipe to separate my data into individual gender dataframes, but this is only one way to do it, and I do find this code very easy to read. However, we could have done the same thing using a traditional R approach of indexing instead.\nhist(df$total[df$gender== 2], col = \u0026#39;orchid\u0026#39;, main = \u0026quot;Histogram of Total scores on Rosenberg Self-Esteem Scale\u0026quot;, xlab = \u0026quot;Total score\u0026quot;) hist(df$total[df$gender==1], add = TRUE, col = \u0026#39;royalblue\u0026#39;, density = 40) Now we have seen the distributions, we might wonder if the sexes differ on the measure of self-esteem. Let’s run a quick t-test to see.\nt.test(men$total, women$total) ## ## Welch Two Sample t-test ## ## data: men$total and women$total ## t = 23.785, df = 37496, p-value \u0026lt; 2.2e-16 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 1.436304 1.694284 ## sample estimates: ## mean of x mean of y ## 27.30897 25.74368 Yes they do! With men having a significantly higher mean score on self-esteem (though the absolute difference is quite small.)\n","date":1570838400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570870182,"objectID":"e4266a814b388528cd91d8ef1a5a6021","permalink":"/post/plotting-multiple-histograms-on-the-same-graph/","publishdate":"2019-10-12T00:00:00Z","relpermalink":"/post/plotting-multiple-histograms-on-the-same-graph/","section":"post","summary":"Recently, while trying to compare the distribution of two samples, I discovered that you can plot both on the same graph in base R, which is a nice feature if you just want to examine the data quickly. We can explore this with a psychological dataset from the Open Psychometrics site. This hosts a range of open psychometric tests and stores the data in an accessible form. Let’s pull out the data for the Rosenberg Self-Esteem Scale (note that there are two different scoring methods in common use on this scale - on the website they have used a 1 - 4 Likert scale for the data output as a csv, but it is not unusual to see the use of a 0 - 3 scale, (which is the method used to give participants on the website feedback) so we need to be cautious when comparing these total scores with published norms (see https://socy.","tags":["R"],"title":"Plotting multiple histograms on the same graph","type":"post"},{"authors":[],"categories":[],"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Christian Ryan","Rosemary MacHale","Emma Hickey"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"229dc2da60b63771c00ba3d3313f3ff8","permalink":"/publication/2018-01-01_forgetting_fam/","publishdate":"2018-01-01T00:00:00Z","relpermalink":"/publication/2018-01-01_forgetting_fam/","section":"publication","summary":"","tags":[],"title":"\"Forgetting Familiar Faces\": Staff Perceptions of Dementia in People with Intellectual Disabilities","type":"publication"},{"authors":["Mohammed Taj-Eldin","Christian Ryan","Brendan O'Flynn","Paul Galvin"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"8d72667e6cb9fa1db620e6a8a28584a3","permalink":"/publication/2018-01-01_a_review_of_we/","publishdate":"2018-01-01T00:00:00Z","relpermalink":"/publication/2018-01-01_a_review_of_we/","section":"publication","summary":"","tags":[],"title":"A Review of Wearable Solutions for Physiological and Emotional Monitoring for Use by People with Autism Spectrum Disorder and Their Caregivers","type":"publication"},{"authors":["Christian Ryan","Elizabeth Quinlan"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"1fbffe26282dc7f7a8b6666109e48284","permalink":"/publication/2018-01-01_whoever_shouts_the_l/","publishdate":"2018-01-01T00:00:00Z","relpermalink":"/publication/2018-01-01_whoever_shouts_the_l/","section":"publication","summary":"","tags":[],"title":"Whoever Shouts the Loudest: Listening to Parents of Children with Disabilities","type":"publication"},{"authors":["Christian Ryan","Shona O'Connor"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"803d371f1b8c0a1d1b6e9ba2f1a7684d","permalink":"/publication/2017-01-01_single_session_psy/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2017-01-01_single_session_psy/","section":"publication","summary":"","tags":[],"title":"Single Session Psychology Clinic for Parents of Children with Autism Spectrum Disorder: A Feasibility Study","type":"publication"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"/project/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"/project/internal-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/internal-project/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Internal Project","type":"project"},{"authors":["Christian Ryan","Philip Furley","Kathleen Mulhall"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"0e5f196caf7a5ead235d282c754fe4aa","permalink":"/publication/2016-01-01_judgments_of_nonve/","publishdate":"2016-01-01T00:00:00Z","relpermalink":"/publication/2016-01-01_judgments_of_nonve/","section":"publication","summary":"","tags":[],"title":"Judgments of Nonverbal Behaviour by Children with High-Functioning Autism Spectrum Disorder: Can They Detect Signs of Winning and Losing from Brief Video Clips?","type":"publication"},{"authors":["Christian Ryan","Martina Stafford","Robert James King"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"193cf3cfe9c92b168335443e485822f1","permalink":"/publication/2016-01-01_brief_report_s/","publishdate":"2016-01-01T00:00:00Z","relpermalink":"/publication/2016-01-01_brief_report_s/","section":"publication","summary":"","tags":[],"title":"Seeing the Man in the Moon: Do Children with Autism Perceive Pareidolic Faces? A Pilot Study","type":"publication"},{"authors":["Christian Ryan","Caitriona Ni Charragain"],"categories":null,"content":"","date":1262304000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1262304000,"objectID":"740ae40ba8903411cb5cfb22c93468cd","permalink":"/publication/2010-01-01_teaching_emotion_r/","publishdate":"2010-01-01T00:00:00Z","relpermalink":"/publication/2010-01-01_teaching_emotion_r/","section":"publication","summary":"","tags":[],"title":"Teaching Emotion Recognition Skills to Children with Autism","type":"publication"},{"authors":["Christian Ryan"],"categories":null,"content":"","date":1167609600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1167609600,"objectID":"0f924f10b9e93ffb784e397d386f8230","permalink":"/publication/2007-01-01_british_outpatient_n/","publishdate":"2007-01-01T00:00:00Z","relpermalink":"/publication/2007-01-01_british_outpatient_n/","section":"publication","summary":"","tags":[],"title":"British Outpatient Norms for the Brief Symptom Inventory","type":"publication"},{"authors":["Christian Ryan"],"categories":null,"content":"","date":1072915200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1072915200,"objectID":"3fa143662e9dbed6b3e97d6484f5696f","permalink":"/publication/2004-01-01_differences_in_the_a/","publishdate":"2004-01-01T00:00:00Z","relpermalink":"/publication/2004-01-01_differences_in_the_a/","section":"publication","summary":"","tags":[],"title":"Differences in the Appraisal of Intrusive Thoughts and Contamination Fears in Obsessive-Compulsive Disorder","type":"publication"}]